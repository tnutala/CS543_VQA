{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS543_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2ZctihXJCjY",
        "colab_type": "text"
      },
      "source": [
        "## Mount Drive (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXl5YdHfMy_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this cell then jump to Importing Libraries to skip mounting drive\n",
        "workdir = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JUQjkOQmw0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw3EQO-MIwIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/CS_543_Final\") # edit as needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmVaruxVJAIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JmN1oa-JMn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "workdir = Path('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz8GKmn4q-xD",
        "colab_type": "text"
      },
      "source": [
        "## Importing libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9UkJZerm0jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install easy-vqa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkTZ5oykpr6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from easy_vqa import get_train_questions, get_test_questions, get_train_image_paths, get_test_image_paths\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwovJdarrCat",
        "colab_type": "text"
      },
      "source": [
        "## Importing data from the Easy-VQA library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riwwCmKJqt4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting answers and image IDs for each question:\n",
        "train_questions, train_answers, train_image_ids = get_train_questions()\n",
        "test_questions, test_answers, test_image_ids = get_test_questions()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZaX8wOJqxxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Printing the first question, answer and image ID: \n",
        "print('Example:')\n",
        "print('Question:', train_questions[0])\n",
        "print('Answer:', train_answers[0])\n",
        "print('Image ID:', train_image_ids[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc-5dYk0rPpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_paths = get_train_image_paths()\n",
        "test_image_paths = get_test_image_paths()\n",
        "\n",
        "train_images = {}\n",
        "test_images = {}\n",
        "\n",
        "for idx in train_image_ids:\n",
        "    train_images[idx] = Image.open(train_image_paths[idx])\n",
        "\n",
        "for idx in test_image_ids:\n",
        "    test_images[idx] = Image.open(test_image_paths[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d9jX9_G5hN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0dVcbfu8g2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj5WXQuT9hl4",
        "colab_type": "text"
      },
      "source": [
        "# Getting Image Features \n",
        "This section will take an image and get its feature vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "287owY7X9lHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import os \n",
        "import csv\n",
        "from time import perf_counter\n",
        "\n",
        "# sample image \n",
        "img =  train_images[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcXn_gzmwMJ0",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a-7Gacgxskq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_to_tensor = tv.transforms.Compose([tv.transforms.ToTensor()])\n",
        "train_tensors = []\n",
        "# transforming each image to tensor to compute mean and std\n",
        "for img in train_images.values():\n",
        "  img_tensor = transform_to_tensor(img)\n",
        "  train_tensors.append(img_tensor)\n",
        "\n",
        "loader = data.DataLoader(train_tensors,\n",
        "                         batch_size=10,\n",
        "                         num_workers=0,\n",
        "                         shuffle=False)\n",
        "\n",
        "train_mean = 0.\n",
        "train_std = 0.\n",
        "\n",
        "for images in loader:\n",
        "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
        "    images = images.view(batch_samples, images.size(1), -1)\n",
        "    train_mean += images.mean(2).sum(0)\n",
        "    train_std += images.std(2).sum(0)\n",
        "\n",
        "train_mean /= len(loader.dataset)\n",
        "train_std /= len(loader.dataset)\n",
        "\n",
        "print(\"train mean, train std: \",train_mean,train_std)\n",
        "# transforming the image \n",
        "transform = tv.transforms.Compose([tv.transforms.ToTensor(),\n",
        "                                   tv.transforms.Normalize(mean=train_mean,std =train_std)])\n",
        "\n",
        "\n",
        "train_dataset = [transform(img) for img in train_images.values()] \n",
        "test_dataset = [transform(img) for img in test_images.values()] \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FuuU9Em_RtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# using a pretrained mask rcnn with a resnet50 backbone\n",
        "rcnn_model = tv.models.detection.maskrcnn_resnet50_fpn(pretrained=True).to(device)\n",
        "# switching to inference mode\n",
        "rcnn_model.eval()\n",
        "\n",
        "# possible modules to use forward hook on\n",
        "print(rcnn_model._modules.keys())\n",
        "\n",
        "# this prints the full model architecture      \n",
        "# print(list(models.model.children())[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YkaHztu_ytZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# options for layer are (['transform', 'backbone', 'rpn', 'roi_heads']) \n",
        "layer = 'rpn'\n",
        "my_module = rcnn_model._modules.get(layer)\n",
        "\n",
        "\n",
        "# Testing the hook with one image\n",
        "img = transform(img)\n",
        "img = img.to(device)\n",
        "# initizialing tensor for storing image features\n",
        "my_embedding = torch.zeros([1000,4])\n",
        "\n",
        "def fun(m, i, o): \n",
        "    \"\"\"takes in the module information (m), inputs (i), and outputs (o) \n",
        "    and determines what is put in the embeddings tensor\"\"\"\n",
        "    my_embedding.copy_(o[0][0]) # declare what to hook here \n",
        "    \n",
        "h = my_module.register_forward_hook(fun)\n",
        "h_x = rcnn_model([img])\n",
        "h.remove()\n",
        "\n",
        "print(\"\\nimage embeddings size: \",my_embedding.size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG9eXJQU619X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if workdir is not None and (workdir / 'preprocessed_images.pt').exists():\n",
        "    preprocessed_images = torch.load(workdir / 'preprocessed_images.pt').to(device)\n",
        "else:\n",
        "    preprocessed_images = []\n",
        "    print(len(train_dataset))\n",
        "    BATCH_SIZE = 1\n",
        "    start = perf_counter()\n",
        "    for i in range(0, len(train_dataset)):\n",
        "        if i % 100 == 0:\n",
        "            print('batch', i)\n",
        "        #image_batch = train_dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        image_batch = train_dataset[i]\n",
        "        if 0 == len(image_batch):\n",
        "            break\n",
        "        # initizialing tensor for storing image features\n",
        "        my_embedding = torch.zeros([1000,4])\n",
        "\n",
        "        h = my_module.register_forward_hook(fun)\n",
        "        h_x = rcnn_model([train_dataset[i].to(device)])\n",
        "        preprocessed_images.append(my_embedding)\n",
        "    preprocessed_images = torch.stack(preprocessed_images)\n",
        "    stop = perf_counter()\n",
        "    print(f\"images preprocess time elapsed: {stop - start:.2f}s\")\n",
        "\n",
        "    if workdir is not None:\n",
        "        preprocessed_images.to(torch.device(\"cpu\"))\n",
        "        p = workdir / 'preprocessed_images.pt'\n",
        "        with p.open(mode='wb') as f:\n",
        "            torch.save(preprocessed_images, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLfUlCzTvRFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if workdir is not None and (workdir / 'test_preprocessed_images.pt').exists():\n",
        "    test_preprocessed_images = torch.load(workdir / 'test_preprocessed_images.pt').to(device)\n",
        "else:\n",
        "    test_preprocessed_images = []\n",
        "    print(len(test_dataset))\n",
        "    BATCH_SIZE = 1\n",
        "    start = perf_counter()\n",
        "    for i in range(0, len(test_dataset)):\n",
        "        if i % 100 == 0:\n",
        "            print('batch', i)\n",
        "        #image_batch = test_dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        image_batch = test_dataset[i]\n",
        "        if 0 == len(image_batch):\n",
        "            break\n",
        "        # initizialing tensor for storing image features\n",
        "        my_embedding = torch.zeros([1000,4])\n",
        "\n",
        "        h = my_module.register_forward_hook(fun)\n",
        "        h_x = rcnn_model([test_dataset[i].to(device)])\n",
        "        test_preprocessed_images.append(my_embedding)\n",
        "    test_preprocessed_images = torch.stack(test_preprocessed_images)\n",
        "    stop = perf_counter()\n",
        "    print(f\"images preprocess time elapsed: {stop - start:.2f}s\")\n",
        "\n",
        "    if workdir is not None:\n",
        "        test_preprocessed_images.to(torch.device(\"cpu\"))\n",
        "        p = workdir / 'test_preprocessed_images.pt'\n",
        "        with p.open(mode='wb') as f:\n",
        "            torch.save(test_preprocessed_images, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPdO4-TN4FBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preprocessed_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKU3YgvSSZbU",
        "colab_type": "text"
      },
      "source": [
        "# Getting Text Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiNtueB0O7wX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from time import perf_counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFtRFHOhSf-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0xfuSd3WrJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_questions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHu3-w0MMZPz",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYbRpJPESose",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if workdir is not None and (workdir / 'preprocessed_questions.pt').exists():\n",
        "    preprocessed_questions = torch.load(workdir / 'preprocessed_questions.pt').to(device)\n",
        "else:\n",
        "    preprocessed_questions = []\n",
        "    print(len(train_questions))\n",
        "    BATCH_SIZE = 64\n",
        "    start = perf_counter()\n",
        "    for i in range(0, len(train_questions)):\n",
        "        if i % 100 == 0:\n",
        "            print('batch', i)\n",
        "        question_batch = train_questions[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        if 0 == len(question_batch):\n",
        "            break\n",
        "        input_pt = tokenizer.batch_encode_plus(question_batch, return_tensors=\"pt\", max_length=12, pad_to_max_length=True)\n",
        "        input_pt.to(device)\n",
        "        with torch.no_grad():\n",
        "            bert_output = bert_model(**input_pt)[0]\n",
        "        preprocessed_questions.append(bert_output)\n",
        "    print(len(preprocessed_questions))\n",
        "    preprocessed_questions = torch.cat(preprocessed_questions)\n",
        "    stop = perf_counter()\n",
        "    print(f\"questions preprocess time elapsed: {stop - start:.2f}s\")\n",
        "\n",
        "    if workdir is not None:\n",
        "        preprocessed_questions.to(torch.device(\"cpu\"))\n",
        "        p = workdir / 'preprocessed_questions.pt'\n",
        "        with p.open(mode='wb') as f:\n",
        "            torch.save(preprocessed_questions, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Q6ORqkvWHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if workdir is not None and (workdir / 'test_preprocessed_questions.pt').exists():\n",
        "    test_preprocessed_questions = torch.load(workdir / 'test_preprocessed_questions.pt').to(device)\n",
        "else:\n",
        "    test_preprocessed_questions = []\n",
        "    print(len(test_questions))\n",
        "    BATCH_SIZE = 64\n",
        "    start = perf_counter()\n",
        "    for i in range(0, len(test_questions)):\n",
        "        if i % 100 == 0:\n",
        "            print('batch', i)\n",
        "        question_batch = test_questions[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        if 0 == len(question_batch):\n",
        "            break\n",
        "        input_pt = tokenizer.batch_encode_plus(question_batch, return_tensors=\"pt\", max_length=12, pad_to_max_length=True)\n",
        "        input_pt.to(device)\n",
        "        with torch.no_grad():\n",
        "            bert_output = bert_model(**input_pt)[0]\n",
        "        test_preprocessed_questions.append(bert_output)\n",
        "    print(len(test_preprocessed_questions))\n",
        "    test_preprocessed_questions = torch.cat(test_preprocessed_questions)\n",
        "    stop = perf_counter()\n",
        "    print(f\"questions preprocess time elapsed: {stop - start:.2f}s\")\n",
        "\n",
        "    if workdir is not None:\n",
        "        test_preprocessed_questions.to(torch.device(\"cpu\"))\n",
        "        p = workdir / 'test_preprocessed_questions.pt'\n",
        "        with p.open(mode='wb') as f:\n",
        "            torch.save(test_preprocessed_questions, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq_E-mKQIcYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preprocessed_questions.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4nerjoffHsI",
        "colab_type": "text"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkVs09H2kE22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from easy_vqa import get_answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP5UShxkrYQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_answers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQjRCOeofLwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VQA(nn.Module):\n",
        "\n",
        "    def __init__(self): \n",
        "        super(VQA, self).__init__()\n",
        "\n",
        "        self.lin_img = nn.Sequential(\n",
        "            nn.Linear(1000*4, 10000),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        \n",
        "        self.lin_ques = nn.Sequential(\n",
        "            nn.Linear(12*768, 10000),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        \n",
        "        self.lin1 = nn.Sequential(\n",
        "            nn.Linear(1*20000, 10000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(10000)\n",
        "            )\n",
        "        \n",
        "        self.lin2 = nn.Sequential(\n",
        "            nn.Linear(1*10000, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(500)\n",
        "            )\n",
        "        \n",
        "        self.lin3 = nn.Linear(1*500, 13)\n",
        "\n",
        "    def forward(self, img, ques, method='concat'):\n",
        "        img = img.view(-1, 1000*4)\n",
        "        img = self.lin_img(img)\n",
        "        #print(img.shape)\n",
        "\n",
        "        ques = ques.view(-1, 12*768)\n",
        "        ques = self.lin_ques(ques)\n",
        "        #print(ques.shape)\n",
        "\n",
        "        if method == 'concat':\n",
        "            x = torch.cat([img, ques], 1)\n",
        "            x = x.view(-1, 1*20000)\n",
        "            x = self.lin1(x)\n",
        "        elif method == 'avg':\n",
        "            x = (img.add(ques))/2\n",
        "            x = x.view(-1, 1*10000)\n",
        "        elif method == 'hadamard':\n",
        "            x = img * ques\n",
        "            x = x.view(-1, 1*10000)\n",
        "        \n",
        "        # x = x.view(-1, 1*20000)\n",
        "        # x = self.lin1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.lin3(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WBc2gO7xHec",
        "colab_type": "text"
      },
      "source": [
        "# Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJD-cLPmK-hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BS = 256\n",
        "TEST_BS = 64\n",
        "\n",
        "cpu = torch.device(\"cpu\")\n",
        "preprocessed_images.to(cpu)\n",
        "preprocessed_questions.to(cpu)\n",
        "test_preprocessed_images.to(cpu)\n",
        "test_preprocessed_questions.to(cpu)\n",
        "\n",
        "train_loader = []\n",
        "test_loader = []\n",
        "answers = get_answers()\n",
        "# convert ['circle', 'green', ...] to {'circle':0, 'green':1, ...}\n",
        "answer2id = dict(zip(answers, range(len(answers))))\n",
        "id2answer = {v:k for (k,v) in answer2id.items()}\n",
        "\n",
        "for i in range(preprocessed_questions.shape[0]):\n",
        "    img_id = train_image_ids[i]\n",
        "    answer_str = train_answers[i]\n",
        "    answer_id = answer2id[answer_str]\n",
        "    train_loader.append((preprocessed_questions[i], preprocessed_images[img_id], answer_id))\n",
        "\n",
        "train_dataloader = data.DataLoader(train_loader, batch_size=TRAIN_BS, \n",
        "                                    shuffle=True, num_workers=0,\n",
        "                                    drop_last=True)\n",
        "\n",
        "for i in range(test_preprocessed_questions.shape[0]):\n",
        "    img_id = test_image_ids[i]\n",
        "    answer_str = test_answers[i]\n",
        "    answer_id = answer2id[answer_str]\n",
        "    test_loader.append((test_preprocessed_questions[i], test_preprocessed_images[img_id], answer_id))\n",
        "\n",
        "test_dataloader = data.DataLoader(test_loader, batch_size=TEST_BS, \n",
        "                                  shuffle=False, num_workers=0,\n",
        "                                  drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVv6JTAssWUZ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwJZO61FsYzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting up GPU:\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "#Calling the model:\n",
        "model = VQA()\n",
        "model.to(device)\n",
        "\n",
        "#Setting the optimizer and loss functions:\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-6)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting variables for training and test loss and accuracies:\n",
        "epochs = 30\n",
        "#predictions = []\n",
        "total = 0\n",
        "correct = 0\n",
        "test_total = 0\n",
        "test_correct = 0\n",
        "epoch_acc = 0\n",
        "epoch_loss = 0\n",
        "epoch_test_acc = 0\n",
        "epoch_test_loss = 0\n",
        "# best_loss = float('inf')\n",
        "log = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    #Training loop:\n",
        "    model.train()\n",
        "    for idx, (question_batch, image_batch, answer_batch) in enumerate(tqdm(train_dataloader)):\n",
        "        question_batch, image_batch, answer_batch = question_batch.to(device), image_batch.to(device), answer_batch.to(device)\n",
        "\n",
        "        #print(image_batch.shape)\n",
        "        #print(question_batch.shape)\n",
        "\n",
        "        pred = model(image_batch, question_batch, method='hadamard') #options for method are 'avg' and 'concat'\n",
        "\n",
        "        loss = loss_fn(pred, answer_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(pred.data, 1)\n",
        "        #predictions.extend(list(predicted.cpu().numpy()))\n",
        "        total += answer_batch.size(0)\n",
        "        correct += (predicted == answer_batch).sum().item()\n",
        "        acc = 100*correct/total\n",
        "\n",
        "        epoch_loss = epoch_loss + loss.item()\n",
        "        epoch_acc = epoch_acc + acc\n",
        "    \n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    truths = []\n",
        "    for idx, (question_batch, image_batch, answer_batch) in enumerate(tqdm(test_dataloader)):\n",
        "        question_batch, image_batch, answer_batch = question_batch.to(device), image_batch.to(device), answer_batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(image_batch, question_batch, method='hadamard') #options for method are 'avg' and 'concat'\n",
        "        loss = loss_fn(pred, answer_batch)\n",
        "        _, predicted = torch.max(pred.data, 1)\n",
        "        predictions.extend(list(predicted.cpu().numpy()))\n",
        "        truths.extend(list(answer_batch.cpu().numpy()))\n",
        "        test_total += answer_batch.size(0)\n",
        "        test_correct += (predicted == answer_batch).sum().item()\n",
        "        test_acc = 100*test_correct/test_total\n",
        "\n",
        "        epoch_test_loss = epoch_test_loss + loss.item()\n",
        "        epoch_test_acc = epoch_test_acc + test_acc\n",
        "    \n",
        "    print('Epoch', epoch+1)\n",
        "    print(f'Training loss: {epoch_loss:.3f}')\n",
        "    print(f'Training accuracy: {acc:.2f}%')\n",
        "    print(f'Validation loss: {epoch_test_loss:.3f}')\n",
        "    print(f'Validation accuracy: {test_acc:.2f}%')\n",
        "    print('---------------------------------------------')\n",
        "    log.append((epoch_loss, acc, epoch_test_loss, test_acc))\n",
        "\n",
        "    # break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJLJyuC5y5Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(truths, predictions)\n",
        "np.savetxt(\"confusion.csv\", cm, delimiter=\",\")\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGzBc2sjz0Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log = np.array(log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZSRFyry27ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"training_log.csv\", log, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE2HsR3J41ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}